{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import gzip\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_folder = '../data/MNIST_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = [\n",
    "[\"training_images\",os.path.join(mnist_data_folder, \"train-images-idx3-ubyte.gz\")],\n",
    "[\"test_images\", os.path.join(mnist_data_folder, \"t10k-images-idx3-ubyte.gz\")],\n",
    "[\"training_labels\", os.path.join(mnist_data_folder, \"train-labels-idx1-ubyte.gz\")],\n",
    "[\"test_labels\", os.path.join(mnist_data_folder, \"t10k-labels-idx1-ubyte.gz\")]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use an offset of 16 bytes while reading the images because the first byte of first image starts from the 16<sup>th</sup> byte.    \n",
    "* Byte 0 to 3: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Header\n",
    "* Byte 4 to 7: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Number of images in file\n",
    "* Byte 8 to 11: &nbsp;&nbsp;&nbsp; Number of rows in each image\n",
    "* Byte 12 to 15: &nbsp;&nbsp; Number of columns in each image\n",
    "\n",
    "#### Similarly we use an offset of 8 bytes while reading labels because the first byte of first label starts from 8<sup>th</sup> byte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = {}\n",
    "for name in filename[:2]:\n",
    "    with gzip.open(name[1], 'rb') as f:\n",
    "        mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1, 28, 28, 1)\n",
    "        \n",
    "for name in filename[-2:]:\n",
    "    with gzip.open(name[1], 'rb') as f:\n",
    "        mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8).reshape(-1, 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['training_images', 'training_labels', 'test_images', 'test_labels'])\n",
      "(60000, 28, 28, 1)\n",
      "(60000, 1)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.keys())\n",
    "print(mnist['training_images'].shape)\n",
    "print(mnist['training_labels'].shape)\n",
    "print(mnist['test_images'].shape)\n",
    "print(mnist['test_labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "(28, 28, 1)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xad07a96a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "index = random.randint(0, len(mnist['training_images']))\n",
    "image = mnist['training_images'][index]\n",
    "label = mnist['training_labels'][index]\n",
    "print(label)\n",
    "print(image.shape)\n",
    "image = image.squeeze()\n",
    "print(image.shape)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(mnist['training_images'], mnist['training_labels'], test_size=0.20, random_state=42)\n",
    "X_test = mnist['test_images']\n",
    "y_test = mnist['test_labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image Shape: (48000, 28, 28, 1)\n",
      "Label Shape: (48000, 1)\n",
      "\n",
      "Training Set:   48000 samples\n",
      "Validation Set: 12000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_validation) == len(y_validation))\n",
    "assert(len(X_test) == len(y_test))\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(X_train.shape))\n",
    "print(\"Label Shape: {}\".format(y_train.shape))\n",
    "print()\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_validation)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LeNet architecture only accepts 32x32xC images, where C is the number of color channels.\n",
    "\n",
    "In order to reformat the MNIST data into a shape that LeNet will accept, we pad the data with two rows of zeros on the top and bottom, and two columns of zeros on the left and right (28+2+2 = 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape: (32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "# np.pad(np_array, ((axis_0 first item, axis_0 second item),(top, bottom),(left, right),(axis_3 first item, axis_3 last item)))\n",
    "X_train      = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_validation = np.pad(X_validation, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test       = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "    \n",
    "print(\"Updated Image Shape: {}\".format(X_train[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
